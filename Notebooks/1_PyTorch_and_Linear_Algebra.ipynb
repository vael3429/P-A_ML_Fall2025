{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1d3c2c",
   "metadata": {},
   "source": [
    "# Introduction to _PyTorch_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b570e",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "_*PyTorch*_ is an open-source deep learning framework developed by Facebook's AI Research lab. It provides a flexible and efficient platform for building and training neural networks, supporting dynamic computation graphs and GPU acceleration. PyTorch is widely used in both academia and industry for research and production due to its intuitive interface and strong community support.\n",
    "\n",
    "For more details, visit the [official PyTorch documentation](https://pytorch.org/docs/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299d1272",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb782d0",
   "metadata": {},
   "source": [
    "In machine learning we will deal with tensors a lot. As a reminder 1-d tensor is a vector (called array in programming jargon); a 2-d tensor is a matrix; if dimentions are k>2 we talk about $k^{th}$-order tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b3c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(12, dtype=torch.float32)\n",
    "print('printing the x vector:', x) \n",
    "# note that in jupyter notebooks, the output of the last line is automatically displayed even without a print statement:\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c20730",
   "metadata": {},
   "source": [
    "### Counting elements, shape and reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b9a035",
   "metadata": {},
   "source": [
    "`numel()` returns the total number of elements in the tensor x, regardless of its shape or dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c36fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.numel() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7454660f",
   "metadata": {},
   "source": [
    "The attribute `x.shape` returns the dimensions (size of each axis) of the tensor x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf8a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c7148",
   "metadata": {},
   "source": [
    "`x.reshape()` is used to change the shape of the tensor x without changing its data, as long as the total number of elements remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb650be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reshape(3, 4) # Reshape to 3 rows and 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3368c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape) #note that this does not change the original tensor! you need to assign it to a new variable or overwrite the original one\n",
    "X = x.reshape(3, 4) # Now x is reshaped\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a93f25",
   "metadata": {},
   "source": [
    "### zeros-, ones- and randn-tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf485ec",
   "metadata": {},
   "source": [
    "`torch.zeros()` creates a tensor filled with zeros, of a specified shape and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecf51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros((2, 3, 4)) # this creates a 3-d tensor of shape (2, 3, 4) filled with zeros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5023b5",
   "metadata": {},
   "source": [
    "`torch.ones()` creates a tensor filled with ones, with the specified shape, and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones((2, 3, 4)) # this creates a 3-d tensor of shape (2, 3, 4) filled with ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3531293a",
   "metadata": {},
   "source": [
    "`torch.randn()` creates a tensor filled with random numbers drawn from a standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a41c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(3, 4) # this creates a 2-d tensor of shape (3, 4) filled with random numbers from a normal distribution with mean 0 and variance 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae8ff0",
   "metadata": {},
   "source": [
    "`torch.tensor()` creates a tensor directly from a Python list, tuple, or NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[2, 1, 4, 3], \n",
    "              [1, 2, 3, 4], \n",
    "              [4, 3, 2, 1]]).shape # Create a 2D tensor with specific values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0421b615",
   "metadata": {},
   "source": [
    "### Indexing and Slicing\n",
    "Indexing and slicing in PyTorch work similarly to NumPy, allowing you to extract, modify, or rearrange parts of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1c19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X #we defined X above, so this will show the reshaped tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0] # Access the first row of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[-1] # Access the last row of the tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4174e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[1:3] # Access rows 1 and 2 of the tensor. Note that index 3 is not included!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9232967",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[1, 2] = 17 # Change the value at row 1, column 2 to 17\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f791d706",
   "metadata": {},
   "source": [
    "-------------------- *YOUR TURN*!!! ----------------\n",
    "\n",
    "Now try to overwrite all values in the first 2 rows of the vector to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e3bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrtite your own code to overwrite all values in the first 2 rows of the vector to 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa7ab71",
   "metadata": {},
   "source": [
    "### Operation between tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c755c89",
   "metadata": {},
   "source": [
    "Element-wise operations \n",
    "1) thourgh unitary scalar operations \n",
    "2) through binary scalar operations \n",
    "3) through broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106c3102",
   "metadata": {},
   "source": [
    "-------------------- *YOUR TURN*!!! ----------------\n",
    "\n",
    "Generate 2 arrays, x and y, on length 5 (aka 5 number of elements each); then try the following operations:\n",
    "x + y, x - y, x * y, x / y, x ** y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e2aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your own code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b220f1d1",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bedcd0",
   "metadata": {},
   "source": [
    "Under certain conditions, even when shapes differ, we can still perform elementwise binary operations by invoking the broadcasting mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0fe989",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e9b0aa",
   "metadata": {},
   "source": [
    "Since a and b are 3 × 1 and 1 × 2 matrices, respectively, their shapes do not match up. Broadcasting produces a larger 3 × 2 matrix by replicating matrix a along the columns and matrix b along the rows before adding them elementwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186ae70e",
   "metadata": {},
   "source": [
    "### Concatenate tensors, logical statements and sum-all-elements operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92959b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be very useful when we will build Convolutional Neural Networks (CNNs) later in the course\n",
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "\n",
    "X, Y, torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35b6e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X == Y # Element-wise comparison between tensors -- returns a tensor of boolean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6746f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.sum(), X.sum(dim=0), X.sum(dim=1) # Sum all elements, sum along rows, sum along columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e246e",
   "metadata": {},
   "source": [
    "### Saving Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6780316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is crucial in machine learning, as models can have millions of parameters, and we need to save memory!\n",
    "before = id(Y) \n",
    "Y=Y+X\n",
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9dfd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = torch.zeros_like(Y)\n",
    "print('id(Z):', id(Z))\n",
    "Z[:] = X + Y\n",
    "print('id(Z):', id(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a79074a",
   "metadata": {},
   "source": [
    "### Conversion to Other Python Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba3050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how you convert a tensor to a numpy array and back \n",
    "A = X.numpy()\n",
    "B = torch.from_numpy(A)\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf4bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how you convert a tensor to a Python list (less used, but still useful)\n",
    "X.tolist(), X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b72f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d221b4f",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a09a1c4",
   "metadata": {},
   "source": [
    "So far, we have been working with synthetic data that arrived in ready-made tensors. \n",
    "\n",
    "However, to apply deep learning in the wild we must extract messy data stored in arbitrary formats, and preprocess it to suit our needs. Fortunately, the pandas library45 can do much of the heavy lifting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89627975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ca6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('''NumRooms,RoofType,Price\n",
    "NA,NA,127500\n",
    "2,NA,106000\n",
    "4,Slate,178100\n",
    "NA,NA,140000''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac23a8b",
   "metadata": {},
   "source": [
    "Before proceeding, look for the file that you just created (in the `data` folder that appeared in your repository). Inspect the `house_tiny.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094a94e",
   "metadata": {},
   "source": [
    "Now, Our first step in processing the dataset is to separate out columns corresponding to input versus target values. \n",
    "We can select columns either by name or via integer-location based indexing (`iloc`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = data.iloc[:, 0:2], data.iloc[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b912d1fc",
   "metadata": {},
   "source": [
    "You might have noticed that pandas replaced all CSV entries with value NA with a spe- cial NaN (not a number) value. This can also happen whenever an entry is empty, e.g., “3„,270000”. These are called missing values and they are the “bed bugs” of data science.\n",
    "\n",
    " missing values might be handled either via \n",
    " - __imputation__ : replaces missing values with estimates of their values \n",
    " - __deletion__  : simply discards either those rows or those columns that contain missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abb9dd0",
   "metadata": {},
   "source": [
    "For categorical input fields, we can treat NaN as a category. Since the `RoofType` column takes values `Slate` and `NaN`, pandas can convert this column into two columns `RoofType_Slate` and `RoofType_nan`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c968aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18c837a",
   "metadata": {},
   "source": [
    "For missing numerical values, one common heuristic is to replace the NaN entries with the mean value of the corresponding column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ce1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477dad1b",
   "metadata": {},
   "source": [
    "Now that all the entries in inputs and targets are numerical, we can load them into a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(inputs.to_numpy(dtype=float))\n",
    "y = torch.tensor(targets.to_numpy(dtype=float))\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afb1db3",
   "metadata": {},
   "source": [
    "## Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb055ea2",
   "metadata": {},
   "source": [
    "### Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91496402",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "x + y, x * y, x / y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d72ef",
   "metadata": {},
   "source": [
    "### vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b99bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that python has a zero-based indexing, so the first element is at index 0\n",
    "x = torch.arange(3)\n",
    "x, x[0], x[1], x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136fe762",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x) # Count the number of elements in the tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edaef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape # Get the shape of the tensor. Note this is a different type the the output of `len(x)`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d099a",
   "metadata": {},
   "source": [
    "### Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcddd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.arange(6).reshape(3, 2)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e228ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.T # Transpose the matrix A. Symmetric matrices are the subset of square matrices that are equal to their own transposes\n",
    "A "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6551e81d",
   "metadata": {},
   "source": [
    "### Tensors and tensor aritmethic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(24).reshape(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = A.clone()  # Assign a copy of A to B by allocating new memory\n",
    "A, A + B # Element-wise addition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f114b",
   "metadata": {},
   "source": [
    "### Element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebccc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A * B # Element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd27dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4) \n",
    "a + X, a * X, (a * X).shape # addition and multiplication with a scalar, and the shape of the resulting tensor (unchanged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529b89f",
   "metadata": {},
   "source": [
    "### Sums of elements in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eaafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of elements in a tensor\n",
    "A.sum(), A.sum(dim=0), A.sum(dim=1) # Sum all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c900610",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.sum(axis=[0, 1]) == A.sum() # Same as A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0833f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.mean(), A.sum() / A.numel() # Mean and average of elements in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0] # Mean and average of elements in a tensor along the first axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b005c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes it can be useful to keep the number of axes unchanged when invoking the func- tion for calculating the sum or mean. \n",
    "# This matters when we want to use the broadcast mechanism.\n",
    "\n",
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "A, A.shape, A.sum(axis=0), A.sum(axis=0).shape, sum_A, sum_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since sum_A keeps its two axes after summing each row, \n",
    "# we can divide A by sum_A with broadcasting to create a matrix where each row sums up to 1.\n",
    "# this is a common technique for normalizing data, expecially for classification tasks, in which\n",
    "# we want to ensure that the sum of probabilities across each row is 1.\n",
    "A / sum_A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08122f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to calculate the cumulative sum of elements of A along some axis, say axis=0, \n",
    "# we can call the cumsum function.\n",
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff4a7f",
   "metadata": {},
   "source": [
    "### Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot product of two vectors\n",
    "x = torch.arange(3, dtype = torch.float32)\n",
    "y = torch.ones(3, dtype = torch.float32)\n",
    "x, y, torch.dot(x, y)\n",
    "# or equivalently\n",
    "torch.sum(x * y) # Element-wise multiplication followed by summation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a5092",
   "metadata": {},
   "source": [
    "### Matrix-vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50616410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix-vector multiplication -- this is a common operation in machine learning, especially in linear layers\n",
    "A.shape, x.shape, torch.mv(A, x), A@x, (A@x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69531c9",
   "metadata": {},
   "source": [
    "### Matrix-matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1168ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix-matrix multiplication\n",
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = torch.ones(3, 4)\n",
    "A, B, torch.mm(A, B), A@B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907b8794",
   "metadata": {},
   "source": [
    "### Norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5d5f53",
   "metadata": {},
   "source": [
    "#### l2 norm (Euclidean norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c3382",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(u * u).sum().sqrt()  #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac97e0",
   "metadata": {},
   "source": [
    "#### l1 norm (Manhattan distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9214a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1ff0b",
   "metadata": {},
   "source": [
    "#### Frobenius norm (l2 norm for matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019166c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = torch.ones((4, 9))\n",
    "D, torch.norm(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8beb08d",
   "metadata": {},
   "source": [
    "-------------------- *YOUR TURN*!!! ----------------\n",
    "\n",
    "Define a vector x of values ranging between -5 and 5. Plot the x^2 and |x|. \n",
    "\n",
    "Looking at the plot, think about what is the effect of l2 and l1 norms of different vectors, how do their norms compare if both are computed as l2 or as l1?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ec168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write you code here. To plotting you can use the python library matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ...code for plotting..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a065f88f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04899b9e",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eefb75b",
   "metadata": {},
   "source": [
    "Use your coding skills to di the following exercizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01407ba",
   "metadata": {},
   "source": [
    "### Ex. 1 -- Prove that the transpose of the transpose of a matrix is the matrix itself \n",
    "\n",
    "$(A^⊤)^⊤ = A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e6428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77f05cea",
   "metadata": {},
   "source": [
    "### Ex. 2 -- Given two matrices A and B, show that sum and transposition commute: \n",
    "\n",
    "$A^⊤ + B^⊤ = (A + B)^⊤$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e6343e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32bb648b",
   "metadata": {},
   "source": [
    "### Ex. 3 -- We defined the tensor X of shape (2, 3, 4) in this section. What is the output of len(X)? Write your answer without implementing any code, then check your answer using code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd338531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07af372d",
   "metadata": {},
   "source": [
    "### Ex 4 -- Consider three matrices, say A, B, C ∈ R100×200. Construct a tensor with three axes by stacking [A, B, C]. What is the dimensionality? Slice out the second coordinate of the third axis to recover B. Check that your answer is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97833eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b118add",
   "metadata": {},
   "source": [
    "### Ex 5 -- Consider three large matrices, say A ∈ R210 ×216 , B ∈ R216 ×25 and C ∈ R25 ×214 , ini- tialized with Gaussian random variables. You want to compute the product ABC. Is there any difference in memory footprint and speed, depending on whether you compute (AB)C or A(BC). Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4687a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A  = ...\n",
    "#B  = ...\n",
    "#C  = ...\n",
    "\n",
    "\n",
    "import tracemalloc\n",
    "\n",
    "# Memory footprint of the product (AB)C\n",
    "tracemalloc.start()\n",
    "AB = torch.mm(A, B)\n",
    "ABC = torch.mm(AB, C)\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(f\"Current memory usage: {current / (1024 * 1024):.5f} MB\")\n",
    "print(f\"Peak memory usage: {peak / (1024 * 1024):.5f} MB\")\n",
    "tracemalloc.stop()\n",
    "\n",
    "# Memory footprint of the product A(BC)\n",
    "tracemalloc.start()\n",
    "BC = torch.mm(B, C)\n",
    "ABC_alt = torch.mm(A, BC)\n",
    "current2, peak2 = tracemalloc.get_traced_memory()\n",
    "print(f\"Current memory usage: {current2 / (1024 * 1024):.5f} MB\")\n",
    "print(f\"Peak memory usage: {peak2 / (1024 * 1024):.5f} MB\")\n",
    "tracemalloc.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ad8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
